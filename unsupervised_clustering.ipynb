{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dfc952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d607c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1\n",
      "CUDA version: 11.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CUDA = True\n",
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "seed = 42\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "if CUDA:\n",
    "    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n",
    "\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f57419bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset, info = tfds.load('colorectal_histology', with_info=True, as_supervised=True)\n",
    "dataset = dataset['train'].batch(len(dataset['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33dc7693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 16:22:38.092014: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Transform the dataset into pytorch\n",
    "for images, labels in dataset:\n",
    "    images_tensor = torch.tensor(images.numpy(), dtype=torch.float)\n",
    "    images_tensor = images_tensor.permute(0, 3, 1, 2)\n",
    "    labels_tensor = torch.tensor(labels.numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39d10f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorectalHistDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].clone().detach()\n",
    "        label = self.labels[idx].clone().detach()\n",
    "\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image)\n",
    "            image2 = self.transform(image)\n",
    "        else:\n",
    "            image1 = image\n",
    "            image2 = image\n",
    "\n",
    "        return image1, image2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94c86e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(dataset, test_size=0.2):\n",
    "\n",
    "    labels = np.array([label for _, _, label in dataset])\n",
    "\n",
    "    # Indices for each class\n",
    "    class_indices = [np.where(labels == class_label)[0] for class_label in np.unique(labels)]\n",
    "\n",
    "    # Split each class's indices into train and test\n",
    "    train_indices, test_indices = [], []\n",
    "    for indices in class_indices:\n",
    "        np.random.shuffle(indices)\n",
    "        split = int(np.floor(test_size * len(indices)))\n",
    "        train_indices.extend(indices[split:])\n",
    "        test_indices.extend(indices[:split])\n",
    "\n",
    "    # Create subset for train and test\n",
    "    train_subset = Subset(dataset, train_indices)\n",
    "    test_subset = Subset(dataset, test_indices)\n",
    "\n",
    "    return train_subset, test_subset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomResizedCrop(size=120),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)], p=0.8),\n",
    "    transforms.GaussianBlur(kernel_size= 5, sigma=(0.1, 2.0)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = ColorectalHistDataset(images_tensor, labels_tensor, transform)\n",
    "train_subset, test_subset = stratified_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b392631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_nce_loss(self, features, batch_size, n_views = 2, temperature = 0.07):\n",
    "\n",
    "    labels = torch.cat([torch.arange(batch_size) for i in range(n_views)], dim=0)\n",
    "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    features = F.normalize(features, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(features, features.T)\n",
    "    # assert similarity_matrix.shape == (\n",
    "    #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
    "    # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "    # discard the main diagonal from both: labels and similarities matrix\n",
    "    mask = torch.eye(labels.shape[0], dtype=torch.bool).to(device)\n",
    "    labels = labels[~mask].view(labels.shape[0], -1)\n",
    "    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "    # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "    # select and combine multiple positives\n",
    "    positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "    # select only the negatives the negatives\n",
    "    negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "    logits = torch.cat([positives, negatives], dim=1)\n",
    "    labels = torch.zeros(logits.shape[0], dtype=torch.long).to(device)\n",
    "\n",
    "    logits = logits / temperature\n",
    "    return logits, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d8e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_model, out_features=512, proj_dim=128):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.encoder = base_model(pretrained=False, num_classes=out_features)\n",
    "        self.encoder.fc = nn.Identity()  # Remove the final layer\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(out_features, 512), nn.ReLU(), nn.Linear(512, proj_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        projections = self.projection_head(features)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc8a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent_loss(z_i, z_j, temperature = 0.07):\n",
    "    cos_sim = torch.matmul(z_i, z_j.T) / temperature\n",
    "    labels = torch.arange(z_i.size(0)).long().to(z_i.device)\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    loss = loss_fct(cos_sim, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89fc46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "base_model = models.resnet18\n",
    "model = SimCLR(base_model).to(device)\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "# Define the optimizer and learning rate scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_subset), eta_min=0, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99b0a6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.9998\n",
      "Epoch [2/100], Loss: 1.0506\n",
      "Epoch [3/100], Loss: 1.0150\n",
      "Epoch [4/100], Loss: 0.9897\n",
      "Epoch [5/100], Loss: 0.9567\n",
      "Epoch [6/100], Loss: 0.9903\n",
      "Epoch [7/100], Loss: 1.0325\n",
      "Epoch [8/100], Loss: 0.9436\n",
      "Epoch [9/100], Loss: 0.9771\n",
      "Epoch [10/100], Loss: 0.9563\n",
      "Epoch [11/100], Loss: 0.9996\n",
      "Epoch [12/100], Loss: 0.9284\n",
      "Epoch [13/100], Loss: 0.9181\n",
      "Epoch [14/100], Loss: 0.9347\n",
      "Epoch [15/100], Loss: 0.9855\n",
      "Epoch [16/100], Loss: 0.9553\n",
      "Epoch [17/100], Loss: 0.9269\n",
      "Epoch [18/100], Loss: 0.9377\n",
      "Epoch [19/100], Loss: 0.9506\n",
      "Epoch [20/100], Loss: 0.9230\n",
      "Epoch [21/100], Loss: 0.9240\n",
      "Epoch [22/100], Loss: 0.9539\n",
      "Epoch [23/100], Loss: 0.9210\n",
      "Epoch [24/100], Loss: 0.8935\n",
      "Epoch [25/100], Loss: 0.9431\n",
      "Epoch [26/100], Loss: 0.9160\n",
      "Epoch [27/100], Loss: 0.9079\n",
      "Epoch [28/100], Loss: 0.9185\n",
      "Epoch [29/100], Loss: 0.9101\n",
      "Epoch [30/100], Loss: 0.9422\n",
      "Epoch [31/100], Loss: 0.8766\n",
      "Epoch [32/100], Loss: 0.8804\n",
      "Epoch [33/100], Loss: 0.9183\n",
      "Epoch [34/100], Loss: 0.9152\n",
      "Epoch [35/100], Loss: 0.8847\n",
      "Epoch [36/100], Loss: 0.8777\n",
      "Epoch [37/100], Loss: 0.8835\n",
      "Epoch [38/100], Loss: 0.8855\n",
      "Epoch [39/100], Loss: 0.9093\n",
      "Epoch [40/100], Loss: 0.8718\n",
      "Epoch [41/100], Loss: 0.8888\n",
      "Epoch [42/100], Loss: 0.8593\n",
      "Epoch [43/100], Loss: 0.8691\n",
      "Epoch [44/100], Loss: 0.8634\n",
      "Epoch [45/100], Loss: 0.8644\n",
      "Epoch [46/100], Loss: 0.8442\n",
      "Epoch [47/100], Loss: 0.8417\n",
      "Epoch [48/100], Loss: 0.8728\n",
      "Epoch [49/100], Loss: 0.8710\n",
      "Epoch [50/100], Loss: 0.8538\n",
      "Epoch [51/100], Loss: 0.8444\n",
      "Epoch [52/100], Loss: 0.8538\n",
      "Epoch [53/100], Loss: 0.8256\n",
      "Epoch [54/100], Loss: 0.8835\n",
      "Epoch [55/100], Loss: 0.8392\n",
      "Epoch [56/100], Loss: 0.8490\n",
      "Epoch [57/100], Loss: 0.7894\n",
      "Epoch [58/100], Loss: 0.7950\n",
      "Epoch [59/100], Loss: 0.8312\n",
      "Epoch [60/100], Loss: 0.8132\n",
      "Epoch [61/100], Loss: 0.8298\n",
      "Epoch [62/100], Loss: 0.8016\n",
      "Epoch [63/100], Loss: 0.8411\n",
      "Epoch [64/100], Loss: 0.8004\n",
      "Epoch [65/100], Loss: 0.8061\n",
      "Epoch [66/100], Loss: 0.8235\n",
      "Epoch [67/100], Loss: 0.8296\n",
      "Epoch [68/100], Loss: 0.7993\n",
      "Epoch [69/100], Loss: 0.8030\n",
      "Epoch [70/100], Loss: 0.8109\n",
      "Epoch [71/100], Loss: 0.7879\n",
      "Epoch [72/100], Loss: 0.7627\n",
      "Epoch [73/100], Loss: 0.8229\n",
      "Epoch [74/100], Loss: 0.7568\n",
      "Epoch [75/100], Loss: 0.7795\n",
      "Epoch [76/100], Loss: 0.7983\n",
      "Epoch [77/100], Loss: 0.8140\n",
      "Epoch [78/100], Loss: 0.7942\n",
      "Epoch [79/100], Loss: 0.7777\n",
      "Epoch [80/100], Loss: 0.7071\n",
      "Epoch [81/100], Loss: 0.7759\n",
      "Epoch [82/100], Loss: 0.7565\n",
      "Epoch [83/100], Loss: 0.8115\n",
      "Epoch [84/100], Loss: 0.7887\n",
      "Epoch [85/100], Loss: 0.7409\n",
      "Epoch [86/100], Loss: 0.7506\n",
      "Epoch [87/100], Loss: 0.7428\n",
      "Epoch [88/100], Loss: 0.7878\n",
      "Epoch [89/100], Loss: 0.7378\n",
      "Epoch [90/100], Loss: 0.7518\n",
      "Epoch [91/100], Loss: 0.7800\n",
      "Epoch [92/100], Loss: 0.7783\n",
      "Epoch [93/100], Loss: 0.7506\n",
      "Epoch [94/100], Loss: 0.7680\n",
      "Epoch [95/100], Loss: 0.7673\n",
      "Epoch [96/100], Loss: 0.7676\n",
      "Epoch [97/100], Loss: 0.7326\n",
      "Epoch [98/100], Loss: 0.7324\n",
      "Epoch [99/100], Loss: 0.7279\n",
      "Epoch [100/100], Loss: 0.7463\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "temperature = 0.07\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (img1, img2, label) in train_loader:\n",
    "        img1, img2 = img1.to(device), img2.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        z_i = model(img1)\n",
    "        z_j = model(img2)\n",
    "\n",
    "        loss = nt_xent_loss(z_i, z_j, temperature)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
    "\n",
    "    # Optionally save your model here with torch.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e3c4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'unsupervised.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
