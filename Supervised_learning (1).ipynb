{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfP669ExBJQH",
    "outputId": "2a697625-13dc-432b-c6fc-3ae6b50ef61f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 15:48:34.702848: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-02 15:48:35.103031: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-02 15:48:36.748515: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 15:48:38.866329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1\n",
      "CUDA version: 11.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, SubsetRandomSampler\n",
    "\n",
    "\n",
    "\n",
    "CUDA = True\n",
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "seed = 42\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "if CUDA:\n",
    "    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n",
    "\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "o5GTwTkUtDkY"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        torch.randn(10).cuda()\n",
    "        break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device kernel image is invalid\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device kernel image is invalid\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "torch.randn(10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "L-NHXxWaBRE3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 19:13:21.287275: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-22 19:13:21.289269: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset, info = tfds.load('colorectal_histology', with_info=True, as_supervised=True)\n",
    "dataset = dataset['train'].batch(len(dataset['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_6pWEXdlBS7N"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 19:13:26.042048: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Transform the dataset into pytorch\n",
    "for images, labels in dataset:\n",
    "    images_tensor = torch.tensor(images.numpy(), dtype=torch.float)\n",
    "    images_tensor = images_tensor.permute(0, 3, 1, 2)\n",
    "    labels_tensor = torch.tensor(labels.numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vejTN1s7BUhe"
   },
   "outputs": [],
   "source": [
    "class ColorectalHistDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].clone().detach()\n",
    "        label = self.labels[idx].clone().detach()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ld5TOFhcBWN-"
   },
   "outputs": [],
   "source": [
    "def stratified_split(dataset, test_size=0.2):\n",
    "\n",
    "    labels = np.array([ins[-1] for ins in dataset])\n",
    "\n",
    "    # Indices for each class\n",
    "    class_indices = [np.where(labels == class_label)[0] for class_label in np.unique(labels)]\n",
    "\n",
    "    # Split each class's indices into train and test\n",
    "    train_indices, test_indices = [], []\n",
    "    for indices in class_indices:\n",
    "        np.random.shuffle(indices)\n",
    "        split = int(np.floor(test_size * len(indices)))\n",
    "        train_indices.extend(indices[split:])\n",
    "        test_indices.extend(indices[:split])\n",
    "\n",
    "    # Create subset for train and test\n",
    "    train_subset = Subset(dataset, train_indices)\n",
    "    test_subset = Subset(dataset, test_indices)\n",
    "\n",
    "    return train_subset, test_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "N-VrtmW_BYOA"
   },
   "outputs": [],
   "source": [
    "# Transformation for supervised learning\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.ToPILImage(),  # Convert numpy array to PIL Image to apply transforms\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Apply horizontal flip with 50% probability\n",
    "    transforms.RandomVerticalFlip(p=0.5),    # Apply vertical flip with 50% probability\n",
    "    transforms.RandomResizedCrop(size=(150, 150), antialias=True),\n",
    "    transforms.ToTensor(),  # Convert PIL Image back to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = ColorectalHistDataset(images_tensor, labels_tensor, transform)\n",
    "train_subset, test_subset = stratified_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zk8gfz5rBaAM",
    "outputId": "ae375471-e956-4159-a96d-df301610a486"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# The base learner\n",
    "\n",
    "class CRCClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super(CRCClassifier, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        resnet18 = models.resnet18(weights=True)\n",
    "        resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)\n",
    "        self.conv_layers = resnet18\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layers(x)\n",
    "\n",
    "model = CRCClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "H2326Q0UBcUi",
    "outputId": "51976c23-8437-4cfe-f4be-ed0f5287a064"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently 41.0% of the train data is being used\n",
      " Epoch Loss: 0.40517078194676376, Max Epoch Acc: 0.8536585365853658\n",
      "Max Validation Loss: 0.5030664069950581, Max Validation Acc: 0.851\n",
      "Currently 42.0% of the train data is being used\n",
      " Epoch Loss: 0.4744964312939417, Max Epoch Acc: 0.8339285714285715\n",
      "Max Validation Loss: 0.5543534895777702, Max Validation Acc: 0.809\n",
      "Currently 43.0% of the train data is being used\n",
      " Epoch Loss: 0.43549591198910115, Max Epoch Acc: 0.8366279069767442\n",
      "Max Validation Loss: 0.49477282106876375, Max Validation Acc: 0.811\n",
      "Currently 44.0% of the train data is being used\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "curr_percentage = 0.01\n",
    "max_epoch_accs = []\n",
    "max_val_accs = []\n",
    "min_val_losses = []\n",
    "min_epoch_losses = []\n",
    "\n",
    "for i in range(41,51):#Loop to run 50 times - 1 for 1% of the train dataset\n",
    "    curr_train_data_len = int(len(train_subset)*curr_percentage*i)\n",
    "    print(f'Currently {curr_percentage*i*100}% of the train data is being used')\n",
    "    indices = torch.randperm(len(train_subset))[:curr_train_data_len]\n",
    "    curr_train_data = Subset(train_subset, indices)\n",
    "    train_loader = DataLoader(curr_train_data, batch_size=40, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(test_subset, batch_size=40, shuffle=False)\n",
    "    model = CRCClassifier().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "    epoch_accs = []\n",
    "    epoch_losses = []\n",
    "    validation_accs = []\n",
    "    validation_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(curr_train_data)\n",
    "        epoch_acc = running_corrects.double() / len(curr_train_data)\n",
    "        epoch_accs.append(epoch_acc.item())\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "      # Validation phase\n",
    "        model.eval()  # Set model to evaluate mode\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "    val_loss = val_loss / len(test_subset)\n",
    "    val_acc = val_corrects.double() / len(test_subset)\n",
    "    validation_losses.append(val_loss)\n",
    "    validation_accs.append(val_acc.item())\n",
    "    max_epoch_idx = np.argmax(epoch_accs)\n",
    "    max_val_idx = np.argmax(validation_accs)\n",
    "    print(f' Epoch Loss: {epoch_losses[max_epoch_idx]}, Max Epoch Acc: {epoch_accs[max_epoch_idx]}')\n",
    "    print(f'Max Validation Loss: {validation_losses[max_val_idx]}, Max Validation Acc: {validation_accs[max_val_idx]}')\n",
    "    max_epoch_accs.append(epoch_accs[max_epoch_idx])\n",
    "    max_val_accs.append(validation_accs[max_val_idx])\n",
    "    min_epoch_losses.append(epoch_losses[max_epoch_idx])\n",
    "    min_val_losses.append(validation_losses[max_val_idx])\n",
    "    with open('sup_val_losses.txt','a+') as f:\n",
    "        for val in min_val_losses:\n",
    "            f.write(f'{val}\\n')\n",
    "    f.close()\n",
    "\n",
    "    with open('sup_epoch_losses.txt','a+') as f:\n",
    "        for val in min_epoch_losses:\n",
    "            f.write(f'{val}\\n')\n",
    "    f.close()\n",
    "\n",
    "    with open('sup_val_accs.txt','a+') as f:\n",
    "        for val in max_val_accs:\n",
    "            f.write(f'{val}\\n')\n",
    "    f.close()\n",
    "\n",
    "    with open('sup_epoch_accs.txt','a+') as f:\n",
    "        for val in max_epoch_accs:\n",
    "            f.write(f'{val}\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aa3D8nmayYpe",
    "outputId": "6a257db3-1026-4f46-e208-2f2ba040aea0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7bd443491690>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sup_val_losses.txt','w') as f:\n",
    "    for val in min_val_losses:\n",
    "        f.write(f'{val}\\n')\n",
    "f.close()\n",
    "\n",
    "with open('sup_epoch_losses.txt','w') as f:\n",
    "    for val in min_epoch_losses:\n",
    "        f.write(f'{val}\\n')\n",
    "f.close()\n",
    "\n",
    "with open('sup_val_accs.txt','w') as f:\n",
    "    for val in max_val_accs:\n",
    "        f.write(f'{val}\\n')\n",
    "f.close()\n",
    "\n",
    "with open('sup_epoch_accs.txt','w') as f:\n",
    "    for val in max_epoch_accs:\n",
    "        f.write(f'{val}\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74IKoug7yaQV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
